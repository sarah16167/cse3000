{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2798066,"sourceType":"datasetVersion","datasetId":1709138}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report, accuracy_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T05:51:17.924519Z","iopub.execute_input":"2025-04-24T05:51:17.924990Z","iopub.status.idle":"2025-04-24T05:51:19.043528Z","shell.execute_reply.started":"2025-04-24T05:51:17.924852Z","shell.execute_reply":"2025-04-24T05:51:19.042501Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"Load Data ","metadata":{}},{"cell_type":"code","source":"# Load the training and testing dataset\ntrain_df = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv')\ntest_df = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T05:51:19.044483Z","iopub.execute_input":"2025-04-24T05:51:19.044953Z","iopub.status.idle":"2025-04-24T05:51:21.109005Z","shell.execute_reply.started":"2025-04-24T05:51:19.044916Z","shell.execute_reply":"2025-04-24T05:51:21.107974Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Define the list of all toxicity-related label columns\nlabels = ['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\n\n#update new label if labels is 1\ntrain_df['label'] = (train_df[labels].sum(axis=1) > 0).astype(int)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T05:51:21.111159Z","iopub.execute_input":"2025-04-24T05:51:21.111482Z","iopub.status.idle":"2025-04-24T05:51:21.146862Z","shell.execute_reply.started":"2025-04-24T05:51:21.111453Z","shell.execute_reply":"2025-04-24T05:51:21.145858Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Count the number of samples in each class label to check for class imbalance\ntrain_df['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T05:51:21.148366Z","iopub.execute_input":"2025-04-24T05:51:21.148685Z","iopub.status.idle":"2025-04-24T05:51:21.161554Z","shell.execute_reply.started":"2025-04-24T05:51:21.148658Z","shell.execute_reply":"2025-04-24T05:51:21.160507Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"label\n0    143346\n1     16225\nName: count, dtype: int64"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"#cleaning (expand contractions, lowercase, strip non-letters)\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r\"what's\", \"what is\", text)\n    text = re.sub(r\"n't\", \" not\", text)\n    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n    return re.sub(r\"\\s+\", \" \", text).strip()\n\ntrain_df['clean_text'] = train_df['comment_text'].apply(clean_text)\ntest_df ['clean_text'] = test_df ['comment_text'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T05:51:21.162702Z","iopub.execute_input":"2025-04-24T05:51:21.163086Z","iopub.status.idle":"2025-04-24T05:51:33.216090Z","shell.execute_reply.started":"2025-04-24T05:51:21.163050Z","shell.execute_reply":"2025-04-24T05:51:33.215141Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Vectorize\nvectorizer = TfidfVectorizer(ngram_range=(1,2),\n                             max_df=0.9, min_df=5,\n                             max_features=10000)\nX = vectorizer.fit_transform(train_df['clean_text'])\ny = train_df['label'].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T05:51:33.216992Z","iopub.execute_input":"2025-04-24T05:51:33.217280Z","iopub.status.idle":"2025-04-24T05:52:04.514839Z","shell.execute_reply.started":"2025-04-24T05:51:33.217253Z","shell.execute_reply":"2025-04-24T05:52:04.513784Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Oversample with SMOTE\nsmote = SMOTE(random_state=42)\nX_res, y_res = smote.fit_resample(X, y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T05:52:04.515940Z","iopub.execute_input":"2025-04-24T05:52:04.516307Z","iopub.status.idle":"2025-04-24T05:55:23.092760Z","shell.execute_reply.started":"2025-04-24T05:52:04.516268Z","shell.execute_reply":"2025-04-24T05:55:23.091947Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Train/validation split\nX_train, X_val, y_train, y_val = train_test_split(\n    X_res, y_res, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T05:55:23.093671Z","iopub.execute_input":"2025-04-24T05:55:23.093936Z","iopub.status.idle":"2025-04-24T05:55:23.195359Z","shell.execute_reply.started":"2025-04-24T05:55:23.093914Z","shell.execute_reply":"2025-04-24T05:55:23.194595Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Fit Naive Bayes\nnb = MultinomialNB()\nnb.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T05:55:23.196175Z","iopub.execute_input":"2025-04-24T05:55:23.196408Z","iopub.status.idle":"2025-04-24T05:55:23.317166Z","shell.execute_reply.started":"2025-04-24T05:55:23.196388Z","shell.execute_reply":"2025-04-24T05:55:23.316141Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"MultinomialNB()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"#Get validation probabilities and apply threshold\ny_val_prob   = nb.predict_proba(X_val)[:,1]          # score\nthreshold    = 0.7\ny_val_label  = (y_val_prob >= threshold).astype(int) # final label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:11:23.480397Z","iopub.execute_input":"2025-04-24T06:11:23.480784Z","iopub.status.idle":"2025-04-24T06:11:23.516539Z","shell.execute_reply.started":"2025-04-24T06:11:23.480753Z","shell.execute_reply":"2025-04-24T06:11:23.515535Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# Evaluate\nprint(\"=== Validation @ threshold =\", threshold, \"===\\n\")\nprint(classification_report(y_val, y_val_label))\nprint(\"Accuracy:\", accuracy_score(y_val, y_val_label))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:11:24.802505Z","iopub.execute_input":"2025-04-24T06:11:24.802926Z","iopub.status.idle":"2025-04-24T06:11:24.926142Z","shell.execute_reply.started":"2025-04-24T06:11:24.802894Z","shell.execute_reply":"2025-04-24T06:11:24.925065Z"}},"outputs":[{"name":"stdout","text":"=== Validation @ threshold = 0.7 ===\n\n              precision    recall  f1-score   support\n\n           0       0.70      0.95      0.81     28441\n           1       0.93      0.60      0.73     28898\n\n    accuracy                           0.78     57339\n   macro avg       0.82      0.78      0.77     57339\nweighted avg       0.82      0.78      0.77     57339\n\nAccuracy: 0.7764000069760547\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"# Score and predict on test set\nX_test       = vectorizer.transform(test_df['clean_text'])\ntest_df['score']           = nb.predict_proba(X_test)[:,1]\ntest_df['predicted_label'] = (test_df['score'] >= threshold).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:11:27.183355Z","iopub.execute_input":"2025-04-24T06:11:27.183736Z","iopub.status.idle":"2025-04-24T06:11:42.925678Z","shell.execute_reply.started":"2025-04-24T06:11:27.183704Z","shell.execute_reply":"2025-04-24T06:11:42.924678Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# Load true test labels\ntestlabel_df = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv')\n\n# Keep only the rows that were actually scored (toxic != -1)\nvalid_labels = testlabel_df[testlabel_df['toxic'] != -1]\n\n# Prepare predictions DataFrame\npredictions_df = test_df[['id', 'predicted_label']].rename(columns={'predicted_label': 'label'})\n\n# Merge on 'id' to align predictions with true labels\nmerged = pd.merge(predictions_df, valid_labels[['id', 'toxic']], on='id')\n\n# Evaluate\nprint(\"=== Test Set Evaluation ===\")\nprint(classification_report(merged['toxic'], merged['label']))\nprint(\"Accuracy:\", accuracy_score(merged['toxic'], merged['label']))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:11:45.788178Z","iopub.execute_input":"2025-04-24T06:11:45.788496Z","iopub.status.idle":"2025-04-24T06:11:46.105780Z","shell.execute_reply.started":"2025-04-24T06:11:45.788471Z","shell.execute_reply":"2025-04-24T06:11:46.104800Z"}},"outputs":[{"name":"stdout","text":"=== Test Set Evaluation ===\n              precision    recall  f1-score   support\n\n           0       0.97      0.91      0.94     57888\n           1       0.48      0.76      0.59      6090\n\n    accuracy                           0.90     63978\n   macro avg       0.73      0.84      0.77     63978\nweighted avg       0.93      0.90      0.91     63978\n\nAccuracy: 0.9002469598924631\n","output_type":"stream"}],"execution_count":53}]}